{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and import of packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pyyaml\n",
    "import sys, os, distutils.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectron 2\n",
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andre pakker\n",
    "\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from google.colab.patches import cv2_imshow\n",
    "import pandas as pd\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "import os\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data.datasets import convert_to_coco_json\n",
    "import shutil\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the images from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import subprocess\n",
    "\n",
    "# Get GitHub token\n",
    "token = getpass(\"Enter your GitHub token: \")\n",
    "\n",
    "# Define repository URL\n",
    "repo_url = f\"https://{token}@github.com/casperbak1/Dataprojekt.git\"\n",
    "\n",
    "# Kloner main branch, og kun seneste commit (depth 1)\n",
    "subprocess.run([\"git\", \"clone\", \"--branch\", \"main\", \"--depth\", \"1\", repo_url])\n",
    "\n",
    "repo_path = \"Dataprojekt\"\n",
    "if os.path.exists(repo_path):  # Hvis der findes en GitHub sti \"Dataprojekt\"\n",
    "    subprocess.run([\"git\", \"sparse-checkout\", \"init\", \"--cone\"], cwd=repo_path) # SÃ¥ klon mappen \"Data/Clean Data/Overbite Data\"\n",
    "    subprocess.run([\"git\", \"sparse-checkout\", \"set\", \"Data/Clean Data/Overbite Data\"], cwd=repo_path)\n",
    "\n",
    "print(\"Repository cloned with only the 'Overbite Data' folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise the data for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotations from the CSV file\n",
    "ANNOTATIONS_FILE = \"Dataprojekt/Data/Clean Data/Overbite Data/Updated_Labels.csv\"\n",
    "annotations_df = pd.read_csv(ANNOTATIONS_FILE)\n",
    "\n",
    "# Sti til dataen\n",
    "DATASET_PATH = \"Dataprojekt/Data/Clean Data/Overbite Data/Annotated Data\"\n",
    "\n",
    "def my_dataset_function():\n",
    "    dataset_dicts = []\n",
    "\n",
    "    # Group annotations by filename (in case multiple keypoints exist for an image)\n",
    "    grouped_annotations = annotations_df.groupby(\"Filename\")\n",
    "\n",
    "    for idx, filename in enumerate(os.listdir(DATASET_PATH)):\n",
    "        if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            record = {}\n",
    "            file_path = os.path.join(DATASET_PATH, filename)\n",
    "\n",
    "            # Read image dimensions\n",
    "            height, width = cv2.imread(file_path).shape[:2]\n",
    "\n",
    "            # Initialize the dataset record\n",
    "            record[\"file_name\"] = file_path\n",
    "            record[\"image_id\"] = idx\n",
    "            record[\"height\"] = height\n",
    "            record[\"width\"] = width\n",
    "\n",
    "            # Default empty annotation list\n",
    "            record[\"annotations\"] = []\n",
    "\n",
    "            # Check if the file has keypoint annotations\n",
    "            if filename in grouped_annotations.groups:\n",
    "                keypoints_list = []\n",
    "                for _, row in grouped_annotations.get_group(filename).iterrows():\n",
    "                    x, y = row[\"X\"], row[\"Y\"]\n",
    "                    keypoints_list.append(x)  # X-coordinate\n",
    "                    keypoints_list.append(y)  # Y-coordinate\n",
    "                    keypoints_list.append(2)  # Visibility flag (0=not visible, 1=occluded, 2=visible)\n",
    "\n",
    "                # Create the annotation entry\n",
    "                annotation = {\n",
    "                    \"bbox\": [0, 0, width, height],  # Dummy bbox covering entire image\n",
    "                    \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                    \"category_id\": 0,  # If you have multiple classes (Vi har 1)\n",
    "                    \"keypoints\": keypoints_list,\n",
    "                    \"num_keypoints\": len(keypoints_list) // 3\n",
    "                }\n",
    "                record[\"annotations\"].append(annotation)\n",
    "\n",
    "            dataset_dicts.append(record)\n",
    "\n",
    "    return dataset_dicts\n",
    "\n",
    "# Register the dataset\n",
    "DatasetCatalog.register(\"Overbite_Data\", my_dataset_function)\n",
    "MetadataCatalog.get(\"Overbite_Data\").set(\n",
    "    thing_classes=[\"object\"],  # Modify for actual class names (Mangler godt navn)\n",
    "    keypoint_names=[\"keypoint\"],  # Name of keypoints (Mangler endnu bedre navn)\n",
    "    keypoint_flip_map=[]  # Add keypoint flip pairs if needed (Nope)\n",
    ")\n",
    "\n",
    "# Test if it works\n",
    "dataset_dicts = DatasetCatalog.get(\"Overbite_Data\")\n",
    "print(f\"Loaded {len(dataset_dicts)} images with keypoints.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion til at hente verifikationsdata\n",
    "def my_validation_function():\n",
    "    dataset_dicts = []\n",
    "    DATASET_PATH = \"Dataprojekt/Data/Clean Data/Overbite Data/Annotated Verification Data\"\n",
    "\n",
    "    grouped_annotations = annotations_df.groupby(\"Filename\")\n",
    "\n",
    "    for idx, filename in enumerate(os.listdir(DATASET_PATH)):\n",
    "        if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            record = {}\n",
    "            file_path = os.path.join(DATASET_PATH, filename)\n",
    "            height, width = cv2.imread(file_path).shape[:2]\n",
    "\n",
    "            record[\"file_name\"] = file_path\n",
    "            record[\"image_id\"] = idx\n",
    "            record[\"height\"] = height\n",
    "            record[\"width\"] = width\n",
    "            record[\"annotations\"] = []\n",
    "\n",
    "            if filename in grouped_annotations.groups:\n",
    "                keypoints_list = []\n",
    "                for _, row in grouped_annotations.get_group(filename).iterrows():\n",
    "                    x, y = row[\"X\"], row[\"Y\"]\n",
    "                    keypoints_list.append(x)\n",
    "                    keypoints_list.append(y)\n",
    "                    keypoints_list.append(2)  # Visibility flag\n",
    "\n",
    "                annotation = {\n",
    "                    \"bbox\": [0, 0, width, height],  # Dummy bbox\n",
    "                    \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                    \"category_id\": 0,\n",
    "                    \"keypoints\": keypoints_list,\n",
    "                    \"num_keypoints\": len(keypoints_list) // 3\n",
    "                }\n",
    "                record[\"annotations\"].append(annotation)\n",
    "\n",
    "            dataset_dicts.append(record)\n",
    "\n",
    "    return dataset_dicts\n",
    "\n",
    "# RegistrÃ©r valideringsdatasÃ¦t\n",
    "DatasetCatalog.register(\"Overbite_Validation\", my_validation_function)\n",
    "MetadataCatalog.get(\"Overbite_Validation\").set(\n",
    "    thing_classes=[\"object\"],\n",
    "    keypoint_names=[\"keypoint\"],\n",
    "    keypoint_flip_map=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrÃ¦ls Warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import os\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.data.datasets import convert_to_coco_json\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data import transforms as T\n",
    "\n",
    "# ----------------------------------------\n",
    "# âœ… Custom Augmentation Mapper\n",
    "# ----------------------------------------\n",
    "from detectron2.structures import Instances\n",
    "\n",
    "def custom_mapper(dataset_dict):\n",
    "    dataset_dict = dataset_dict.copy()\n",
    "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "\n",
    "    aug = [\n",
    "        T.ResizeShortestEdge(short_edge_length=(640, 720, 768), max_size=1024, sample_style='choice'),\n",
    "        T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
    "        T.RandomRotation(angle=[-15, 15], expand=True, center=None, sample_style='range'),  \n",
    "        T.RandomApply(\n",
    "        T.RandomSaturation(intensity_min=0.7, intensity_max=1.3),\n",
    "        prob = 0.5),  \n",
    "        T.RandomBrightness(0.9, 1.1),\n",
    "        T.RandomContrast(0.9, 1.1),\n",
    "    ]\n",
    "    image, transforms = T.apply_transform_gens(aug, image)\n",
    "    image_tensor = torch.as_tensor(image.transpose(2, 0, 1).copy(), dtype=torch.float32)\n",
    "    dataset_dict[\"image\"] = image_tensor\n",
    "\n",
    "    annos = [utils.transform_instance_annotations(\n",
    "        obj, transforms, image.shape[:2],\n",
    "        keypoint_hflip_indices=[0]\n",
    "    ) for obj in dataset_dict[\"annotations\"]]\n",
    "\n",
    "    # ðŸ‘‡ The critical fix\n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict[\"instances\"] = instances\n",
    "    return dataset_dict\n",
    "# ----------------------------------------\n",
    "# âœ… Custom Trainer w/ Eval + Augmentations\n",
    "# ----------------------------------------\n",
    "class CustomTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name):\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
    "\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=custom_mapper)\n",
    "\n",
    "# ----------------------------------------\n",
    "# âœ… Config Setup\n",
    "# ----------------------------------------\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"Overbite_Data\",)\n",
    "cfg.DATASETS.TEST = (\"Overbite_Validation\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 8\n",
    "cfg.SOLVER.IMS_PER_BATCH = 16\n",
    "cfg.SOLVER.BASE_LR = 0.002\n",
    "\n",
    "cfg.SOLVER.MAX_ITER = 90000\n",
    "cfg.SOLVER.STEPS = (60000, 80000)  # Decrease LR after 60k and 80k iters\n",
    "cfg.SOLVER.GAMMA = 0.1            # Typical LR decay factor\n",
    "\n",
    "cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "cfg.SOLVER.WARMUP_METHOD = \"linear\"\n",
    "cfg.SOLVER.WARMUP_FACTOR = 1.0 / 1000\n",
    "\n",
    "cfg.SOLVER.AMP.ENABLED = True\n",
    "\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_CONV = 8\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.CONV_DIMS = [512, 512, 512, 512, 512, 512, 512, 512]\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.HEATMAP_SIZE = 64   # or 56, 80, etc.\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.UP_SCALE = 2        # typical upsampling factor\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.KEYPOINT_ON = True\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_KEYPOINTS = 1\n",
    "\n",
    "cfg.TEST.KEYPOINT_OKS_SIGMAS = [0.1]\n",
    "cfg.TEST.EVAL_PERIOD = 10000\n",
    "\n",
    "cfg.OUTPUT_DIR = \"./output/Overbite_Model\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ----------------------------------------\n",
    "# âœ… COCO Conversion for Validation Set\n",
    "# ----------------------------------------\n",
    "coco_annotation_path = os.path.join(cfg.OUTPUT_DIR, \"Overbite_Validation_coco_format.json\")\n",
    "convert_to_coco_json(\"Overbite_Validation\", coco_annotation_path)\n",
    "print(f\"Validation set converted to COCO format: {coco_annotation_path}\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# âœ… Training\n",
    "# ----------------------------------------\n",
    "trainer = CustomTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "\n",
    "# ----------------------------------------\n",
    "# âœ… Final Evaluation\n",
    "# ----------------------------------------\n",
    "val_loader = build_detection_test_loader(cfg, \"Overbite_Validation\")\n",
    "inference_on_dataset(trainer.model, val_loader, COCOEvaluator(\"Overbite_Validation\", cfg, False, output_dir=cfg.OUTPUT_DIR))\n",
    "\n",
    "print(\"âœ… Training and validation completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
