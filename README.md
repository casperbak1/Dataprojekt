# Overbidsklassificering ‚Äî Automatisering og standardisering  
*Et maskinl√¶ringsprojekt til klassificering af overbid ud fra 3D-scanninger og billeder.*

---

## Table of Contents

- [Hurtigt Overblik](#hurtigt-overblik)
- [Projektbeskrivelse](#projektbeskrivelse)
  - [Abstract](#abstract)
  - [Introduktion](#introduktion)
  - [Data og Databehandling](#data-og-databehandling)
    - [Databehandling](#databehandling)
    - [Data](#data)
  - [CNN-netv√¶rk](#cnn-netv√¶rk)
  - [Pixel-matrix](#pixel-matrix)
  - [Evalueringsmetoder](#evalueringsmetoder)
  - [Resultater](#resultater)
  - [Pipeline](#pipeline)
- [Folder Structure](#folder-structure)
---

## Hurtigt Overblik over filstruktur

- **Data:** Indeholder alle r√• og forarbejdede CSV- og PNG-filer, prim√¶rt brugt til tr√¶ning og test.
- **Overbite:** Indeholder kode, scripts, outputs og forskellige versioner brugt til overbite-klassificering.
- **Pipeline:** Viser hele workflowet fra 3D .PLY-fil til keypoint-placering.

---

## Mappe struktur
<details open>
  <summary>üìÅ Dataprojekt/</summary>
  <ul>
    <li>üìÑ .gitignore</li>
    <li>üìÑ Model.txt</li>
    <li>üìÑ README.md</li>
    <li>
      <details>
        <summary>üìÅ Data/</summary>
        <ul>
          <li>üìÑ pixel_flip_formula.png</li>
          <li>üìÑ Splitting_and_flipping_of_images.ipynb</li>
        </ul>
      </details>
    </li>
    <li>
      <details>
        <summary>üìÅ Overbite/</summary>
        <ul>
          <li>
            <details>
              <summary>üìÅ Kode/</summary>
              <ul>
                <li>üìÑ Overbite.ipynb</li>
                <li>üìÑ Pixel_Matrix_Optimizer.ipynb</li>
                <li>üìÑ Test_Model.ipynb</li>
                <li>üìÑ Train_Model.ipynb</li>
              </ul>
            </details>
          </li>
        </ul>
      </details>
    </li>
  </ul>
</details>


---

# Projektbeskrivelse

## Indholdsfortegnelse

- Abstract
- Introduktion
- Data og databehandling
- CNN-netv√¶rk
- Resultater
- Pipeline

---

## Abstract

*Automatisering og standardisering af overbidsklassificering gennem maskinl√¶ring og billedbehandling.*

---

## Introduktion

I tandl√¶gepraksis findes der ikke √©n standardiseret metode til m√•ling af overbid. Nogle anvender √∏jem√•l, andre lineal, r√∏ntgenbilleder eller 3D-scanninger. Alle metoder har fordele og ulemper, men ofte er der en afvejning mellem pr√¶cision og tidsforbrug.

**Dette projekt har to hovedfokusomr√•der:**

1. Udvikling og tr√¶ning af maskinl√¶ringsmodeller til pr√¶cis overbidsklassificering.
2. Udarbejdelse af en pipeline, der g√•r fra 3D-filer (.PLY) til keypoint-markering, der muligg√∏r automatisk m√•ling.

**Bem√¶rk:** Resten af denne projektbeskrivelse omhandler kun punkt 1. Pipeline beskrives separat i sektionen "Pipeline".

Projektet bygger p√• et offentligt datas√¶t best√•ende af 1.351 tredimensionelle intraorale scanninger. Til dette projekt er 3D-scanningerne konverteret til todimensionelle billeder, hvilket g√∏r det muligt at anvende g√¶ngse deep-learning-metoder til billedanalyse. 

Som model anvender vi Keypoint R-CNN, en videreudvikling af Mask R-CNN, der er designet til at finde pr√¶cise keypoints i billeder. Ved at kombinere regions¬≠forslag med punktdetektion g√∏r modellen det muligt at identificere n√∏jagtige punkter p√• t√¶nder, hvilket er afg√∏rende for vores opgave, da overbid m√•les som den vertikale afstand mellem to pr√¶cise punkter p√• fort√¶nderne.

---

## Data og Databehandling

### Databehandling

Projektet startede med **1351 kombinerede billeder** (3 vinkler pr. patient):

<img src="Data/Figurer/00OMSZGW_lower_combined.png" width="800" height="250"/>

> *Billede af underk√¶be fra 3 vinkler*

Til billederne var der **1166 annoteringer**, eksempelvis:

| Filename                       | X1  | Y1  | X2   | Y2  |
|---------------------------------|-----|-----|------|-----|
| 00OMSZGW_lower_combined.png     | 777 | 492 | 2310 | 487 |

#### M√•l for databehandling:

1. Split kombinerede billeder til tre separate billeder (left, middle, right)
2. Fordel billeder i mapper: **Bolton Data** og **Overbite Data**
3. Ensret orientering og koordinationer i "Overbite Data" (ved transponering)
4. Grupp√©r data som billed-par
5. Del data i tr√¶ning, test, verifikation, og uannoteret data

#### Step 1: Opdeling af billeder

<table>
  <tr>
    <td><img src="Data/Figurer/Lower_Right.png" width="250" height="250"/></td>
    <td><img src="Data/Figurer/Lower_Middle.png" width="250" height="250"/></td>
    <td><img src="Data/Figurer/Lower_Left.png" width="250" height="250"/></td>
  </tr>
</table>


#### Step 2: Sortering

- **Left/Right** billeder ‚Üí *Overbite Data*
- **Middle** billede ‚Üí *Bolton Data*

#### Step 3: Ensretning

"Right" billedet transponeres (flippes), s√• orienteringen matcher "Left" billedet, og koordinater justeres:\

<table>
  <tr>
    <td><img src="Data/Figurer/Lower_Right.png" width="400" height="400"/></td>
    <td><img src="Data/Figurer/Lower_Left_Flipped.png" width="400" height="400"/></td>
  </tr>
</table>

> Keypoint/Annoteringen er markeret med r√∏d p√• de 2 billeder

Koordinatet justeres s√• med f√∏lgende formel:
`x' = w - 1 - x`\
Her er `x = X2 = 2310` fra originalen, w = 3072 fra originalen, og derfor er det nye x beregnet til:\
`x' = 3072 - 1 - 2310 = 761`

Og den nye CSV vil derfor blive til:

| Filename                   | X1  | Y1  |
|----------------------------|-----|-----|
| 00OMSZGW_lower_left.png   | 777 | 492 |
| 00OMSZGW_lower_right.png    | 761 | 487 |


#### Step 4 + 5: Par og grupper

- Et *par* = 4 billeder med koordinater (left/right, upper/lower)
- Ufuldst√¶ndige par ‚Üí *Unannotated Data Pairs*
- Resten inddeles i:
    - *Annotated Data Pairs* (tr√¶ning)
    - *Annotated Verication data* (verifikation under tr√¶ning)
    - *Annotated Test data* (test efter tr√¶ning)

> Outliers og fejl rettes i CSV efter databehandling.  
> Alt databehandling findes i `Splitting_and_flipping_of_images.ipynb`.


---

Oversigt over fordelingen af billeder:

| Folder                               | Image count | Patient count | Annotated |
|---------------------------------------|-------------|-------------|-------------|
| Bolton Data                          | 1351        | 675 | No |
| Overbite Data                        | 2702        | 675 | NaN |
| Overbite Data/Annotated Data Pairs   | 1580        | 395 | Yes |
| Overbite Data/Annotated Verication data | 100      | 25 | Yes |
| Overbite Data/Annotated Test data    | 300         | 75 | Yes |
| Overbite Data/Unannotated Data Pairs | 722         | 180 | NaN|

Efter dataen er opdelt i mapper mangler vi kun 2 ting inden tr√¶ningen kan p√•begynde:

1. Ops√¶tte en bounding boks
2. Konvertere annoteringer til "COCO JSON" format

Vi ops√¶tter en bounding boks for at hj√¶lpe med at lokalisere objektet af interesse. Det hj√¶lper modellen med at finde det omr√•de den skal fokusere p√•, for at lave forudsigelser. Dette g√∏r modellen mere pr√¶cis og effektiv.

Annoteringerne skal til sidst konverteres til et format som kan l√¶ses af modellen.

Modellen modtager alts√• som input til tr√¶ning 1580 billeder af f√∏lgende format:

<img src="Data/Figurer/Data_For_Training.png" width="600" height="600"/>

> *Keypoint markeret med r√∏d, og bounding box markeret med gr√•*

Og annoteringen:

```json
{
  "images": [
    {
      "file_name": "Dataprojekt/Data/Clean Data/Overbite Data/Annotated Data Pairs/00OMSZGW_lower_left.png",
      "height": 1024,
      "width": 1024,
      "id": 0
    }
  ],
  "annotations": [
    {
      "bbox": [740, 492, 62, 125],
      "bbox_mode": 1,
      "category_id": 0,
      "keypoints": [777, 492, 2],
      "num_keypoints": 1,
      "image_id": 0,
      "id": 0
    }
  ],
  "categories": [
    {
      "id": 0,
      "name": "tooth",
      "keypoints": ["apex"],
      "skeleton": []
    }
  ]
}
```

Modellen er alts√• nu klar til at blive tr√¶net.


---

## Keypoints R-CNN-netv√¶rk

Vi tr√¶nede vores model ved at benytte os af en forudtr√¶net model fra Detectron2.\
Den model vi har anvendt hedder "keypoint_rcnn_X_101_32x8d_FPN_3x".\
Modellen er alts√• en Keypoint R-CNN model hvor X_101_32x8d_FPN er selve backbone-arkitekturen:\
X_101_32x8d betyder ResNeXt-101 (101 lag) med 32 grupper og en bredde p√• 8 per gruppe\
FPN st√•r for Feature Pyramid Network, hvilket betyder, at modellen bruger flere ‚Äúfeature-maps‚Äù p√• forskellige skalaer\

Den grundl√¶ggende m√•de vores tr√¶ning har k√∏rt p√• er:

Vi starter med billeder af st√∏rrelsen 1024x1024 som hver har et ground truth keypoint.
Det n√¶ste der sker er at billederne bliver augmenteret p√• forskellige m√•der, f.eks. med andre billedst√∏rrelser, spejlinger, lys- og kontrastjusteringer s√• modellen ikke kun l√¶rer et specifikt udseende. Annoteringerne f√∏lger selvf√∏lgelig med spejlinger osv.
Denne augmentering er med til at g√∏re modellen mere robust.

Det n√¶ste der sker er at vi indl√¶ser billederne i batches.
Dette g√∏r vi fordi at havde vi kun taget et billede af gangen, havde vi f√•et langsommere tr√¶ning og en mere ustabil tr√¶ning.
N√•r vi tr√¶ner modellen med en batch str. p√• 16, s√• vil modellens v√¶gte blive opdateret p√• gennemsnittet af fejlen for hele batchen. Havde vi nu kun brugt 1 billede af gangen, s√• ville modellens v√¶gte blive opdateret p√• baggrund af fejlen for dette ene billede og havde billedet nu v√¶ret en outlier, s√• ville modellens v√¶gte alts√• blive opdateret i retning af en outlier.

Efter augmentering og batch indl√¶sning kommer vi til ResNeXt-101, dette er selve CNN delen.
Her har vi 101 lag, som hver laver en convulution.
Hver enkelt convulution bliver s√• indelt i 32 grupper.
De 32 grupper finder s√• m√∏nstre.
Efter ResNeXt-101 ender vi op med en masse "Feature maps" hvor hver pixel svarer til styrken af et bestemt m√∏nster i billedet.

Nu har vi en masse feature maps og det er her FPN kommer ind i billedet.
FPN samler feature maps fra alle de forskellige lag.
De tidligste lag finder de helt sm√• m√∏nstre, og de sene lag finder helhedderne.

Vi er nu ankommet til RPN (Region Proposal Network).
RPN foresl√•r tusindvis af sm√• bokse med forskellige st√∏rrelser og former alle  de steder, hvor der kan v√¶re noget sp√¶ndende.
For hver enkelt af disse bokse scorer RPN, hvor sandsynligt det er, at boksen indeholder et objekt. De bedste forslag g√•r videre til n√¶ste skridt.

Vi er nu ved at v√¶re ved vejs ende.
For hver af de vidersendte forslag fra RPN skaber modellen et heatmap hvor hver pixel viser sandsynligheden for at vores keypoint ligger der.
Sandsynlighederne laves med en softmax-funktion, s√• de summer til 1.
S√• tager modellen den pixel p√• heatmappet, hvor sandsynligheden er h√∏jest, da det er modellens bedste bud p√• keypointets placering.

Til sidst er der loss, backpropagation og optimering.
Efter modellen har givet sit bedste bud p√• hvor keypointet skal placeres, s√• beregnes det hvor galt den tog fejl, med en cross-entropy loss mellem predicted og ground truth.
Efter det sker der backpropagation;
Den starter med fejlen og regner, hvor meget hver v√¶gt i netv√¶rket har p√•virket fejlen, dette sker lag-for-lag bagud gennem hele netv√¶rket med k√¶dereglen for differenciering.
V√¶gtene justeres en smule, s√• fejlen bliver mindre n√¶ste gang.
Det her gentager vi for hver batch indtil modellen er konvergeret.

---

## Pixel-matrix

Efter modellen har placeret keypoints p√• billederne, finjusteres disse positioner ved hj√¶lp af pixels√∏gning. Dette sker ved at definere en matrix (af forudbestemt st√∏rrelse) omkring det keypoint, som modellen har forudsagt. Inden for denne matrix identificeres den pixel, der ligger h√∏jest og er lysest, og denne pixel v√¶lges herefter som det nye, justerede keypoint. Hvis der findes to pixels med samme v√¶rdi, bliver den pixel, der ligger l√¶ngst til venstre, valgt. Dette valg bygger p√• hvordan det sande keypoint bliver annoteret. 
Form√•let med denne proces er at sikre, at keypointet placeres s√• pr√¶cist som muligt ud fra det forudsagte keypoint fra modellen, hvilket forbedrer den samlede n√∏jagtighed og robusthed af keypoint placeringen.

Figuren viser fordelingen af fejl for placeringen af keypoints efter pixels√∏gningen er implementeret.

<img src="Data/Figurer/Histogram_efter_pixelmatrix.png" width="900" height="400"/> 

## Evalueringsmetoder

Til evaluering af modellen har vi benyttet os af tre metoder:

1. **Mean radial error (MRE)**
2. **Succesful detection rate (SDR)**
3. **Weighted Cohen‚Äôs kappa**

De er defineret som f√∏lger:

**Mean radial error**:

$$
MRE = \frac{\sum_{i=1}^N R_i}{N}
$$

Her er \$N\$ antallet af predikterede punkter, og \$R\_i\$ er den euklidiske afstand mellem ground truth og modellens punkt.

MRE giver os indsigt i, hvor t√¶t modellens forudsigelser i gennemsnit ligger p√• det korrekte punkt (ground truth). Jo lavere MRE, desto mere pr√¶cis er modellens gennemsnitlige punktplacering.

**Succesful detection rate**:

$$
SDR = \frac{K}{N} \cdot 100
$$

Her er \$N\$ antallet af predikterede punkter, og \$K\$ er antallet af korrekt placerede punkter indenfor et tilladt "fejl"-interval. Vi har brugt intervaller, der tillader 0.5, 1 og 2 mm afstand i forhold til ground truth.

SDR viser, hvor stor en andel af modellens forudsigelser der ligger indenfor et givent toleranceniveau fra ground truth (fx 0.5, 1 eller 2 mm). Det er s√¶rligt nyttigt, hvis man vil vide, hvor ofte modellen rammer ‚Äútilstr√¶kkeligt t√¶t‚Äù p√• det korrekte punkt, givet at man accepterer en vis fejlmargin.

**Weighted Cohen‚Äôs kappa** (\$\kappa\_w\$) bruges til at m√•le, hvor god overensstemmelse der er mellem modellens klassifikation og den sande (ekspert-annoterede) klasse, hvor tilf√¶ldig overensstemmelse er korrigeret for:

$$
\kappa_w = 1 - \frac{\sum_{i,j} w_{i,j} O_{i,j}}{\sum_{i,j} w_{i,j} E_{i,j}}
$$

Her er \$O\_{i,j}\$ andelen af tilf√¶lde, hvor ground truth er klasse \$i\$ og modellen valgte klasse \$j\$, og \$E\_{i,j}\$ er den forventede andel af s√•danne tilf√¶lde, hvis annotatorerne var uafh√¶ngige.

V√¶gtene \$w\_{i,j}\$ bruges til at straffe st√∏rre fejl h√•rdere. Ved **kvadratisk v√¶gtning** (‚Äúquadratic weights‚Äù) beregnes v√¶gten som:

$$
w_{i,j} = \left( \frac{i - j}{k - 1} \right)^2
$$

hvor \$k\$ er antallet af klasser (her 5 for ‚ÄúA‚Äù‚Äì‚ÄúE‚Äù).

Det vil sige, at hvis modellen forveksler ‚ÄúA‚Äù og ‚ÄúE‚Äù, t√¶ller det som en st√∏rre fejl end hvis den forveksler ‚ÄúA‚Äù og ‚ÄúB‚Äù.

---

## Resultater 
### Detection Metrics (g√¶lder for alle tests)

| SDR (‚â§ 0.5 mm) | SDR (‚â§ 1 mm) | SDR (‚â§ 2 mm) | Mean Radial Error (MRE) |
|----------------|--------------|--------------|--------------------------|
| 89.33 %        | 96.00 %      | 99.00 %      | 0.22 mm                  |

### Test Results

| Summary Name                | Classification Accuracy | Weighted Cohen's Kappa | Patients Total | Patients Excluded |
|----------------------------|--------------------------|------------------------|----------------|-------------------|
| Overbite_Classification1.csv | 97.22 %                 | 0.9927                 | 75             | 3                 |
| Overbite_Classification2.csv | 94.44 %                 | 0.9841                 | 75             | 3                 |
| Overbite_Classification3.csv | 95.89 %                 | 0.9906                 | 75             | 2                 |
| Overbite_Classification4.csv | 95.83 %                 | 0.9906                 | 75             | 3                 |
| Overbite_Classification5.csv | 94.59 %                 | 0.9860                 | 75             | 1                 |
| Overbite_Classification6.csv | 94.59 %                 | 0.9875                 | 75             | 1                 |
| Overbite_Classification7.csv | 95.89 %                 | 0.9894                 | 75             | 2                 |
| Overbite_Classification8.csv | 94.52 %                 | 0.9882                 | 75             | 2                 |
| Overbite_Classification9.csv | 97.30 %                 | 0.9935                 | 75             | 1                 |
| Overbite_Classification10.csv| 93.15 %                 | 0.9836                 | 75             | 2                 |


## Pipeline
Som den sidste del af projektet har vi udviklet en pipeline, der tager to PLY-filer ‚Äî √©n for overk√¶ben og √©n for underk√¶ben ‚Äî som input. Pipelinen giver som output en visuel forudsigelse af det samlede tands√¶t samt en klassifikation af overbid.

Den f√∏rste version af pipelinen byggede p√• kode, som vores vejleder havde stillet til r√•dighed, oprindeligt udviklet af en postdoc. Denne kode accepterede √©n enkelt PLY-fil og genererede to billeder: √©t, der viste t√¶nderne fra venstre side, og √©t fra h√∏jre side.

Vi udvidede og √¶ndrede koden, s√• den nu tager to PLY-filer (over- og underk√¶be) som input. Vores tilf√∏jelser omfatter:

‚Ä¢ Justering og ensretning af billederne

‚Ä¢ K√∏rsel af modellen til overbidsklassifikation

‚Ä¢ Fremstilling af et endeligt output, der viser b√•de de forudsagte keypoints og klassifikationsresultatet

P√• nuv√¶rende tidspunkt kan vi ikke evaluere pipelinens ydeevne p√• virkelige eksempler. For at pipelinen kan give n√∏jagtige forudsigelser, skal b√•de over- og underk√¶bemodellerne v√¶re i samme koordinatsystem. Denne justering findes dog ikke i de PLY-filer, vi har til r√•dighed.


## Referencer 

Ben-Hamadou, Achraf, Neifar, Nour, Rekik, Ahmed, Smaoui, Oussama, Bouzguenda, Firas, Pujades, Sergi, Boyer, Edmond, and Ladroit, Edouard. "Teeth3Ds+: An Extended Benchmark for Intra-oral 3D Scans Analysis." arXiv preprint arXiv:2210.06094 (2022). https://arxiv.org/abs/2210.06094

