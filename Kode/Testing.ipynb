{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and downloads of packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!python -m pip install pyyaml\n",
    "import sys, os, distutils.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Detectron 2\n",
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Andre pakker\n",
    "\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from google.colab.patches import cv2_imshow\n",
    "import pandas as pd\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "import os\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data.datasets import convert_to_coco_json\n",
    "import shutil\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab.patches import cv2_imshow\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model from GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images from github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_folder = \"Dataprojekt/Data/Clean Data/Overbite Data/Annotated Verification Data\" # Change folder for other images\n",
    "\n",
    "def test_dataset_function():\n",
    "    dataset_dicts = []\n",
    "    for idx, filename in enumerate(os.listdir(test_folder)):\n",
    "        if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            record = {}\n",
    "            file_path = os.path.join(test_folder, filename)\n",
    "\n",
    "            height, width = cv2.imread(file_path).shape[:2]\n",
    "            record[\"file_name\"] = file_path\n",
    "            record[\"image_id\"] = idx\n",
    "            record[\"height\"] = height\n",
    "            record[\"width\"] = width\n",
    "            record[\"annotations\"] = []  # Ingen annotations (ren test data)\n",
    "\n",
    "            dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "\n",
    "DatasetCatalog.register(\"my_test_dataset\", test_dataset_function)\n",
    "MetadataCatalog.get(\"my_test_dataset\").set(thing_classes=[\"object\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option to remove dataset\n",
    "\n",
    "dataset_name = \"test_dataset\"\n",
    "if dataset_name in DatasetCatalog.list():\n",
    "    DatasetCatalog.remove(dataset_name)\n",
    "if dataset_name in MetadataCatalog.list():\n",
    "    MetadataCatalog.pop(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Reinitialize config\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")) # Husk at bruge korrekt backbone\n",
    "cfg.MODEL.WEIGHTS = os.path.join(\"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Confidence threshold\n",
    "cfg.MODEL.KEYPOINT_ON = True\n",
    "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_KEYPOINTS = 1  # Match træning\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "print(\"Model reloaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# File paths\n",
    "labels_file = \"Dataprojekt/Data/Clean Data/Overbite Data/Updated_Labels.csv\"\n",
    "image_folder = \"Dataprojekt/Data/Clean Data/Overbite Data/Annotated Verification Data\"\n",
    "output_csv = \"final_results_with_distance.csv\"\n",
    "\n",
    "# Conversion\n",
    "PIXEL_TO_MM = 0.08\n",
    "\n",
    "# Load metadata and test dataset\n",
    "dataset_dicts = DatasetCatalog.get(\"my_test_dataset\")\n",
    "metadata = MetadataCatalog.get(\"my_test_dataset\")\n",
    "\n",
    "# === LOAD GROUND TRUTH LABELS ===\n",
    "ground_truth = {}\n",
    "with open(labels_file, mode=\"r\", newline=\"\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header\n",
    "    for row in reader:\n",
    "        filename, x, y = [col.strip() for col in row]\n",
    "        filename = os.path.splitext(filename)[0]  # remove extension\n",
    "        ground_truth[filename] = (float(x), float(y))\n",
    "\n",
    "# === MAIN LOOP: Predict, Match, Save, Visualize ===\n",
    "rows = [[\"Filename\", \"X_True\", \"Y_True\", \"X_Model\", \"Y_Model\", \"Euc_dist\", \"mm_Dist\"]]\n",
    "\n",
    "for sample in dataset_dicts:\n",
    "    img_path = sample[\"file_name\"]\n",
    "    filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "    if filename not in ground_truth:\n",
    "        print(f\"⚠️ No ground truth for: {filename}\")\n",
    "        continue\n",
    "\n",
    "    # Read image and run prediction\n",
    "    img = cv2.imread(img_path)\n",
    "    outputs = predictor(img)\n",
    "\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    if not instances.has(\"pred_keypoints\"):\n",
    "        print(f\"❌ No keypoints found in: {filename}\")\n",
    "        continue\n",
    "\n",
    "    keypoints = instances.pred_keypoints\n",
    "    if len(keypoints) == 0:\n",
    "        print(f\"⚠️ Empty keypoint list in: {filename}\")\n",
    "        continue\n",
    "\n",
    "    # Assume first instance\n",
    "    pred_x, pred_y, _ = keypoints[0][0].tolist()\n",
    "    true_x, true_y = ground_truth[filename]\n",
    "\n",
    "    # Distance\n",
    "    euc_dist = round(math.sqrt((true_x - pred_x) ** 2 + (true_y - pred_y) ** 2), 2)\n",
    "    mm_dist = round(euc_dist * PIXEL_TO_MM, 2)\n",
    "\n",
    "    # Save to CSV row\n",
    "    rows.append([filename, true_x, true_y, pred_x, pred_y, euc_dist, mm_dist])\n",
    "\n",
    "    # === VISUALIZE ===\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.scatter(true_x, true_y, color=\"blue\", marker=\"o\", s=3, label=f\"True ({true_x}, {true_y})\")\n",
    "    plt.scatter(pred_x, pred_y, color=\"red\", marker=\"x\", s=3, label=f\"Model ({pred_x}, {pred_y})\")\n",
    "    plt.legend(title=f\"Dist: {euc_dist} px ({mm_dist} mm)\")\n",
    "    plt.title(f\"Comparison: {filename}\")\n",
    "    plt.show()\n",
    "\n",
    "# === SAVE FINAL CSV ===\n",
    "with open(output_csv, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"✅ Final results saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distrubution of distances to True point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# File path\n",
    "matched_predictions_file = \"final_results_with_distance.csv\"\n",
    "\n",
    "# Read distance values\n",
    "distances_mm = []\n",
    "with open(matched_predictions_file, mode=\"r\", newline=\"\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip first header\n",
    "    next(reader)  # Skip second header\n",
    "\n",
    "    for row in reader:\n",
    "        distance_mm = float(row[-1])  # Last column is \"Distance (mm)\"\n",
    "        distances_mm.append(distance_mm)\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(distances_mm, bins=35, color=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Distance Error (mm)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Prediction Errors (mm)\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
