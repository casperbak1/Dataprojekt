{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760b5023-df86-4ca9-a129-26a9490f53b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  2.6 ; cuda:  cu121\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a1d8deb-990a-40fa-9ee4-90767fdc944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data.datasets import convert_to_coco_json\n",
    "import shutil\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5930c01a-3eeb-4914-add9-b219df5d0bad",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac7fa4e-51eb-4be3-942f-646b857c8601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='my_test_dataset', thing_classes=['object'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to test data\n",
    "test_folder = os.path.join(\"..\", \"..\", \"Data\", \"Clean Data\", \"Overbite Data\", \"Annotated Test data\") # Change folder for other images\n",
    "\n",
    "# This function loads the test dataset\n",
    "def test_dataset_function():\n",
    "    dataset_dicts = []\n",
    "    for idx, filename in enumerate(os.listdir(test_folder)):\n",
    "        if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            record = {}\n",
    "            file_path = os.path.join(test_folder, filename)\n",
    "\n",
    "            height, width = cv2.imread(file_path).shape[:2]\n",
    "            record[\"file_name\"] = file_path\n",
    "            record[\"image_id\"] = idx\n",
    "            record[\"height\"] = height\n",
    "            record[\"width\"] = width\n",
    "            record[\"annotations\"] = []  # No annotations for test dataset\n",
    "\n",
    "            dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "\n",
    "DatasetCatalog.register(\"my_test_dataset\", test_dataset_function)\n",
    "MetadataCatalog.get(\"my_test_dataset\").set(thing_classes=[\"object\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "697f1469-d7de-4f1f-8db7-d3f0d99dc73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 15:19:33 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ..\\Output\\Modeller\\NyeBilleder\\model_0054999.pth ...\n",
      "Model reloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "# Reinitialize config and model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = os.path.join(\"..\", \"Output\", \"Modeller\", \"NyeBilleder\", \"model_0054999.pth\")  # Path to the trained model\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.95\n",
    "cfg.MODEL.KEYPOINT_ON = True\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_KEYPOINTS = 1 # Change this to the number of keypoints in your dataset (1 in our case)\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "print(\"Model reloaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21817622-f1e4-48a8-ac4f-3bee35d74f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# File paths to ground truth labels and test image folder\n",
    "labels_file = os.path.join(\"..\", \"..\", \"Data\", \"Clean Data\", \"Overbite Data\", \"Updated_Labels.csv\")\n",
    "image_folder = os.path.join(\"..\", \"..\", \"Data\", \"Clean Data\", \"Overbite Data\", \"Annotated Test data\")\n",
    "output_csv = os.path.join(\"..\", \"Output\", \"Keypoint Placement\", \"final_results_with_distance_54999_Nye.csv\")\n",
    "\n",
    "# Conversion from pixels to mm\n",
    "PIXEL_TO_MM = 0.08\n",
    "\n",
    "# Load metadata and test dataset \n",
    "dataset_dicts = DatasetCatalog.get(\"my_test_dataset\")\n",
    "metadata = MetadataCatalog.get(\"my_test_dataset\")\n",
    "\n",
    "# === LOAD GROUND TRUTH LABELS ===\n",
    "ground_truth = {}\n",
    "with open(labels_file, mode=\"r\", newline=\"\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header\n",
    "    for row in reader:\n",
    "        filename, x, y = [col.strip() for col in row]\n",
    "        filename = os.path.splitext(filename)[0]  # remove extension \n",
    "        ground_truth[filename] = (float(x), float(y))\n",
    "\n",
    "# === MAIN LOOP: Predict, Match, Save, Visualize ===\n",
    "\n",
    "# Initialize CSV rows\n",
    "rows = [[\"Filename\", \"X_True\", \"Y_True\", \"X_Model\", \"Y_Model\", \"Euc_dist\", \"mm_Dist\"]]\n",
    "\n",
    "# Loop through each image in the dataset\n",
    "for sample in tqdm(dataset_dicts, desc=\"Processing images\", dynamic_ncols=True):  # tqdm with ETA\n",
    "    img_path = sample[\"file_name\"]\n",
    "    filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "    if filename not in ground_truth:\n",
    "        print(f\"No ground truth for: {filename}\")\n",
    "        continue\n",
    "\n",
    "    # Read image and run prediction\n",
    "    img = cv2.imread(img_path)\n",
    "    outputs = predictor(img)\n",
    "    \n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    if not instances.has(\"pred_keypoints\"):\n",
    "        print(f\"No keypoints found in: {filename}\")\n",
    "        continue\n",
    "    \n",
    "    keypoints = instances.pred_keypoints\n",
    "    if len(keypoints) == 0:\n",
    "        print(f\"Empty keypoint list in: {filename}\")\n",
    "        continue\n",
    "\n",
    "    # Assume first instance\n",
    "    pred_x, pred_y, _ = keypoints[0][0].tolist()\n",
    "    true_x, true_y = ground_truth[filename]\n",
    "\n",
    "    # Distance calculations \n",
    "    euc_dist = round(math.sqrt((true_x - pred_x) ** 2 + (true_y - pred_y) ** 2), 2)\n",
    "    mm_dist = round(euc_dist * PIXEL_TO_MM, 2)\n",
    "\n",
    "    # Save to CSV row\n",
    "    rows.append([filename, true_x, true_y, pred_x, pred_y, euc_dist, mm_dist])\n",
    "\n",
    "    '''# === VISUALIZE with bbox ===\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img_rgb)\n",
    "\n",
    "    # Plot ground truth keypoint (blue circle)\n",
    "    plt.scatter(true_x, true_y, color=\"blue\", marker=\"o\", s=20, label=f\"True ({true_x}, {true_y})\")\n",
    "\n",
    "    # Plot predicted keypoint (red cross)\n",
    "    plt.scatter(pred_x, pred_y, color=\"red\", marker=\"x\", s=30, label=f\"Model ({pred_x}, {pred_y})\")\n",
    "\n",
    "    # Plot predicted bbox (green rectangle)\n",
    "    if instances.has(\"pred_boxes\"):\n",
    "        pred_box = instances.pred_boxes.tensor[0].tolist()  # Assume first instance\n",
    "        x1, y1, x2, y2 = map(int, pred_box)\n",
    "        plt.gca().add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1,\n",
    "                                          edgecolor=\"green\", facecolor=\"none\", linewidth=2, label=\"Pred BBox\"))\n",
    "\n",
    "    plt.legend(title=f\"Dist: {euc_dist} px ({mm_dist} mm)\")\n",
    "    plt.title(f\"Comparison: {filename}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()'''\n",
    "\n",
    "# === SAVE FINAL CSV ===\n",
    "with open(output_csv, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Final results saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505dc085-d2e5-4b85-a7e4-7a1edecf55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === CONFIGURATION ===\n",
    "matched_predictions_file = os.path.join(\"..\", \"Output\", \"Keypoint Placement\", \"final_results_with_distance_54999_Nye.csv\")\n",
    "image_folder = os.path.join(\"..\", \"..\", \"Data\", \"Clean Data\", \"Overbite Data\", \"Annotated Test data\")\n",
    "error_threshold_mm = 1.0\n",
    "PIXEL_TO_MM = 0.08  # In case you want to reverse-calculate\n",
    "image_extension = \".png\"  # Change to .jpg if needed\n",
    "\n",
    "# === LOAD DATA FROM CSV ===\n",
    "distances_mm = []\n",
    "high_error_rows = []\n",
    "\n",
    "with open(matched_predictions_file, mode=\"r\", newline=\"\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header row 1\n",
    "    next(reader)  # Skip header row 2\n",
    "\n",
    "    for row in reader:\n",
    "        filename, true_x, true_y, pred_x, pred_y, euc_dist, mm_dist = row\n",
    "        mm_dist = float(mm_dist)\n",
    "        distances_mm.append(mm_dist)\n",
    "\n",
    "        if mm_dist > error_threshold_mm:\n",
    "            high_error_rows.append({\n",
    "                \"filename\": filename,\n",
    "                \"true_x\": float(true_x),\n",
    "                \"true_y\": float(true_y),\n",
    "                \"pred_x\": float(pred_x),\n",
    "                \"pred_y\": float(pred_y),\n",
    "                \"euc_dist\": float(euc_dist),\n",
    "                \"mm_dist\": mm_dist\n",
    "            })\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "exclude_outliers = True\n",
    "max_error_for_histogram = 40.0  # mm – only relevant if exclude_outliers is True\n",
    "\n",
    "\n",
    "# === PLOT HISTOGRAM ===\n",
    "if exclude_outliers:\n",
    "    distances_for_hist = [d for d in distances_mm if d <= max_error_for_histogram]\n",
    "    print(f\"Excluding outliers > {max_error_for_histogram} mm. Showing {len(distances_for_hist)} entries.\")\n",
    "else:\n",
    "    distances_for_hist = distances_mm\n",
    "    print(f\"Showing all {len(distances_mm)} entries in histogram.\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(distances_for_hist, bins=35, color=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "plt.xlabel(\"Distance Error (mm)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Prediction Errors (mm)\")\n",
    "plt.show()\n",
    "\n",
    "# === DISPLAY HIGH-ERROR IMAGES ===\n",
    "for row in high_error_rows:\n",
    "    filename = row[\"filename\"]\n",
    "    img_path = os.path.join(image_folder, filename + image_extension)\n",
    "\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\" Image not found: {img_path}\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.scatter(row[\"true_x\"], row[\"true_y\"], color=\"blue\", marker=\"o\", s=3, label=f\"True ({row['true_x']}, {row['true_y']})\")\n",
    "    plt.scatter(row[\"pred_x\"], row[\"pred_y\"], color=\"red\", marker=\"x\", s=3, label=f\"Model ({row['pred_x']}, {row['pred_y']})\")\n",
    "    plt.legend(title=f\"Dist: {row['euc_dist']} px ({row['mm_dist']} mm)\")\n",
    "    plt.title(f\"Comparison: {filename}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
